{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73f0c6a4",
   "metadata": {},
   "source": [
    "# DataWig Examples\n",
    "\n",
    "## Installation\n",
    "\n",
    "Clone the repository from git and set up virtualenv in the root dir of the package:\n",
    "\n",
    "```\n",
    "python3 -m venv venv\n",
    "```\n",
    "\n",
    "Install the package from local sources:\n",
    "\n",
    "```\n",
    "./venv/bin/pip install -e .\n",
    "```\n",
    "\n",
    "## Running DataWig\n",
    "The DataWig API expects your data as a [pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html). Here is an example of how the dataframe might look:\n",
    "\n",
    "|Product Type | Description           | Size | Color |\n",
    "|-------------|-----------------------|------|-------|\n",
    "|   Shoe      | Ideal for Running     | 12UK | Black |\n",
    "| SDCards     | Best SDCard ever ...  | 8GB  | Blue  |\n",
    "| Dress       | This **yellow** dress | M    | **?** |\n",
    "\n",
    "DataWig let's you impute missing values in two ways:\n",
    "  * A `.complete` functionality inspired by [`fancyimpute`](https://github.com/iskandr/fancyimpute)\n",
    "  * A `sklearn`-like API with `.fit` and `.predict` methods\n",
    "\n",
    "## Quickstart Example\n",
    "\n",
    "### Using `AutoGluonImputer.complete`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7968d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This allows to import datawig\n",
    "from pathlib import Path\n",
    "import sys,os\n",
    "path_root = Path(os.getcwd()).parents[2]\n",
    "sys.path.append(str(path_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19d5d7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'precision_threshold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k9/jm95_7614xz7nrvh6p08fl6r0000gn/T/ipykernel_9290/3126494702.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# impute missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdf_with_missing_imputed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatawig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoGluonImputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_with_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f(x) with_missing'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_with_missing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f(x)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/datawig/datawig/autogluon_imputer.py\u001b[0m in \u001b[0;36mcomplete\u001b[0;34m(data_frame, precision_threshold, numeric_confidence_quantile, inplace, time_limit, verbosity)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0midx_missing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 imputer = AutoGluonImputer(input_columns=input_cols,\n\u001b[0m\u001b[1;32m    221\u001b[0m                                         \u001b[0moutput_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                                         \u001b[0mprecision_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'precision_threshold'"
     ]
    }
   ],
   "source": [
    "import os, random, warnings\n",
    "import numpy as np\n",
    "import datawig\n",
    "\n",
    "random.seed(0)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# generate some data with simple nonlinear dependency\n",
    "df = datawig.utils.generate_df_numeric() \n",
    "# mask 10% of the values\n",
    "df_with_missing = df.mask(np.random.rand(*df.shape) > .8)\n",
    "\n",
    "# impute missing values\n",
    "df_with_missing_imputed = datawig.AutoGluonImputer.complete(df_with_missing)\n",
    "\n",
    "df['f(x) with_missing'] = df_with_missing['f(x)']\n",
    "df['f(x) imputed'] = df_with_missing_imputed['f(x)']\n",
    "df[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ae30d",
   "metadata": {},
   "source": [
    "### Using `AutoGluonImputer.fit` and `.predict`\n",
    "\n",
    "You can also impute values in specific columns only (called `output_column` below) using values in other columns (called `input_columns` below). DataWig currently supports imputation of categorical columns and numeric columns. Type inference is based on ``pandas`` \n",
    "\n",
    "#### Imputation of categorical columns\n",
    "\n",
    "Let's first generate some random strings hidden in longer random strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e14c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['f(x) with_missing'] = df_with_missing['f(x)']\n",
    "df['f(x) imputed'] = df_with_missing_imputed['f(x)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44b079a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cMbm9 j7c1f RebhO BctvV m6Kop NQqEe</td>\n",
       "      <td>m6Kop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7zOfb O2NiT RwL85 Rz1TH G7Fgt m6Kop</td>\n",
       "      <td>m6Kop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             sentences  label\n",
       "0  cMbm9 j7c1f RebhO BctvV m6Kop NQqEe  m6Kop\n",
       "1  7zOfb O2NiT RwL85 Rz1TH G7Fgt m6Kop  m6Kop"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = datawig.utils.generate_df_string( num_samples=200, \n",
    "                                       data_column_name='sentences', \n",
    "                                       label_column_name='label')\n",
    "df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "340a2ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/felix/code/datawig/datawig/autogluon_imputer.py\u001b[0m(176)\u001b[0;36mpredict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    174 \u001b[0;31m                \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    175 \u001b[0;31m                \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 176 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_threshold\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    177 \u001b[0;31m                    \u001b[0mabove_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabove_precision\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    178 \u001b[0;31m                        \u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_thresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/felix/code/datawig/datawig/autogluon_imputer.py\u001b[0m(179)\u001b[0;36mpredict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    177 \u001b[0;31m                    \u001b[0mabove_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabove_precision\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    178 \u001b[0;31m                        \u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_thresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 179 \u001b[0;31m                \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mabove_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_column\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimputation_suffix\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    180 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    181 \u001b[0;31m            \u001b[0mimputations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/felix/code/datawig/datawig/autogluon_imputer.py\u001b[0m(172)\u001b[0;36mpredict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    170 \u001b[0;31m            \u001b[0mimputations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    171 \u001b[0;31m            \u001b[0mprobas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 172 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_thresholds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    173 \u001b[0;31m                \u001b[0mabove_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimputations\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    174 \u001b[0;31m                \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m/Users/felix/code/datawig/datawig/autogluon_imputer.py\u001b[0m(176)\u001b[0;36mpredict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    174 \u001b[0;31m                \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    175 \u001b[0;31m                \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 176 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_threshold\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    177 \u001b[0;31m                    \u001b[0mabove_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabove_precision\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    178 \u001b[0;31m                        \u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_thresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>label</th>\n",
       "      <th>label_imputed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>PFTP5 IripW Wa0RH lm0lc Z9jZI DOBx3</td>\n",
       "      <td>Z9jZI</td>\n",
       "      <td>Z9jZI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>O67IM lm0lc DdZ04 RwL85 n5RL0 Z9jZI</td>\n",
       "      <td>Z9jZI</td>\n",
       "      <td>Z9jZI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>CH4F6 2V9SM Cffu4 Z9jZI zfx1h Rn9Xd</td>\n",
       "      <td>Z9jZI</td>\n",
       "      <td>Z9jZI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>vvYxT lm0lc Z9jZI wy1Qq NQqEe OCyT4</td>\n",
       "      <td>Z9jZI</td>\n",
       "      <td>Z9jZI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ERA5K YkvB0 IlnyL Svkpo Z9jZI RwL85</td>\n",
       "      <td>Z9jZI</td>\n",
       "      <td>Z9jZI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sentences  label label_imputed\n",
       "57   PFTP5 IripW Wa0RH lm0lc Z9jZI DOBx3  Z9jZI         Z9jZI\n",
       "31   O67IM lm0lc DdZ04 RwL85 n5RL0 Z9jZI  Z9jZI         Z9jZI\n",
       "65   CH4F6 2V9SM Cffu4 Z9jZI zfx1h Rn9Xd  Z9jZI         Z9jZI\n",
       "140  vvYxT lm0lc Z9jZI wy1Qq NQqEe OCyT4  Z9jZI         Z9jZI\n",
       "89   ERA5K YkvB0 IlnyL Svkpo Z9jZI RwL85  Z9jZI         Z9jZI"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = datawig.utils.random_split(df)\n",
    "\n",
    "imputer = datawig.AutoGluonImputer(\n",
    "    input_columns=['sentences'], # column(s) containing information about the column we want to impute\n",
    "    output_column='label' # the column we'd like to impute values for\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer.fit(train_df=df_train, time_limit=100)\n",
    "\n",
    "#Impute missing values and return original dataframe with predictions\n",
    "imputed = imputer.predict(df_test)\n",
    "imputed.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc36df6",
   "metadata": {},
   "source": [
    "#### Imputation of numerical columns\n",
    "\n",
    "Imputation of numerical values works just like for categorical values.\n",
    "\n",
    "Let's first generate some numeric values with a quadratic dependency:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eeb3ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.895813</td>\n",
       "      <td>3.617395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.008764</td>\n",
       "      <td>1.024857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.978105</td>\n",
       "      <td>3.919697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.638216</td>\n",
       "      <td>6.965940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.480706</td>\n",
       "      <td>6.151376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y\n",
       "0  1.895813  3.617395\n",
       "1 -1.008764  1.024857\n",
       "2  1.978105  3.919697\n",
       "3 -2.638216  6.965940\n",
       "4  2.480706  6.151376"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datawig\n",
    "\n",
    "df = datawig.utils.generate_df_numeric( num_samples=200, \n",
    "                                        data_column_name='x', \n",
    "                                        label_column_name='y')         \n",
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0663c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.464692</td>\n",
       "      <td>2.149859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-2.687957</td>\n",
       "      <td>7.225748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2.226667</td>\n",
       "      <td>4.958026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2.124441</td>\n",
       "      <td>4.502884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-0.434246</td>\n",
       "      <td>0.176235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            x         y\n",
       "57   1.464692  2.149859\n",
       "31  -2.687957  7.225748\n",
       "65   2.226667  4.958026\n",
       "140  2.124441  4.502884\n",
       "89  -0.434246  0.176235"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = datawig.utils.random_split(df)\n",
    "\n",
    "imputer = datawig.AutoGluonImputer(\n",
    "    input_columns=['x'], # column(s) containing information about the column we want to impute\n",
    "    output_column='y', # the column we'd like to impute values for\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer.fit(train_df=df_train, time_limit=100)\n",
    "\n",
    "#Impute missing values and return original dataframe with predictions\n",
    "imputed = imputer.predict(df_test)\n",
    "imputed.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b67617f9-db55-4cd3-9e23-6dcc5eb5c88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.datasets import (\n",
    "    load_diabetes,\n",
    "    load_wine,\n",
    "    make_hastie_10_2\n",
    ")\n",
    "\n",
    "def get_data(data_fn, noise=3e-1):\n",
    "    X, y = data_fn(n_samples=10000)\n",
    "    X = X + np.random.randn(*X.shape) * noise\n",
    "    return pd.DataFrame(np.vstack([X.T, y]).T, columns= [str(i) for i in range(X.shape[-1] + 1)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0566e03f-3715-4a29-8791-93100deca2e0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "X = get_data(make_hastie_10_2)\n",
    "label = X.columns[-1]\n",
    "X[label] = X[label].astype(str)\n",
    "features = X.columns[:-1]\n",
    "df_train, df_test = datawig.utils.random_split(X.copy())\n",
    "\n",
    "imputer = datawig.AutoGluonImputer(\n",
    "    input_columns=[x for x in X.columns if x != label], # column(s) containing information about the column we want to impute\n",
    "    output_column=label, # the column we'd like to impute values for\n",
    "    verbosity=2,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c38576d-a6e6-43df-bf34-b2d00fc52ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 10s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20211130_205043/\"\n",
      "AutoGluon Version:  0.3.1\n",
      "Train Data Rows:    7200\n",
      "Train Data Columns: 10\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6111.98 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.58 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['0', '1', '2', '3', '4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.58 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6480, Val Rows: 720\n",
      "Excluded Model Types: ['GBM', 'XGB']\n",
      "\tFound 'GBM' model in hyperparameters, but 'GBM' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'GBM' model in hyperparameters, but 'GBM' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'GBM' model in hyperparameters, but 'GBM' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'XGB' model in hyperparameters, but 'XGB' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 9.91s of the 9.9s of remaining time.\n",
      "\t0.6986\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 9.84s of the 9.83s of remaining time.\n",
      "\t0.6986\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 9.77s of the 9.76s of remaining time.\n",
      "\t0.8361\t = Validation score   (accuracy)\n",
      "\t1.47s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 8.18s of the 8.17s of remaining time.\n",
      "\t0.8417\t = Validation score   (accuracy)\n",
      "\t1.83s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 6.23s of the 6.22s of remaining time.\n",
      "\t0.8764\t = Validation score   (accuracy)\n",
      "\t1.56s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 4.67s of the 4.66s of remaining time.\n",
      "\t0.8569\t = Validation score   (accuracy)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 3.75s of the 3.74s of remaining time.\n",
      "\t0.8583\t = Validation score   (accuracy)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 2.83s of the 2.82s of remaining time.\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 12)\n",
      "\t0.8792\t = Validation score   (accuracy)\n",
      "\t2.79s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ... Training model for up to 0.0s of the -0.01s of remaining time.\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 9.91s of the -0.68s of remaining time.\n",
      "\t0.8875\t = Validation score   (accuracy)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11.0s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20211130_205043/\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<datawig.autogluon_imputer.AutoGluonImputer at 0x7fe2661e2070>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit an imputer model on the train data\n",
    "imputer.fit(train_df=df_train, time_limit=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30995068-83fc-49ba-a6cb-d45ad1cfab1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10_imputed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>0.735197</td>\n",
       "      <td>0.712926</td>\n",
       "      <td>0.677537</td>\n",
       "      <td>0.446614</td>\n",
       "      <td>0.447349</td>\n",
       "      <td>-0.597103</td>\n",
       "      <td>-1.025037</td>\n",
       "      <td>-1.020038</td>\n",
       "      <td>-1.814596</td>\n",
       "      <td>-0.194096</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>-0.338972</td>\n",
       "      <td>-1.593443</td>\n",
       "      <td>0.584711</td>\n",
       "      <td>-0.310341</td>\n",
       "      <td>0.204547</td>\n",
       "      <td>1.566984</td>\n",
       "      <td>0.813121</td>\n",
       "      <td>-0.818627</td>\n",
       "      <td>0.449865</td>\n",
       "      <td>1.788736</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>-1.910418</td>\n",
       "      <td>2.056198</td>\n",
       "      <td>1.126950</td>\n",
       "      <td>0.831595</td>\n",
       "      <td>-2.170040</td>\n",
       "      <td>0.654610</td>\n",
       "      <td>-1.919194</td>\n",
       "      <td>-2.352304</td>\n",
       "      <td>-1.861600</td>\n",
       "      <td>-0.765301</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9806</th>\n",
       "      <td>0.470405</td>\n",
       "      <td>0.425514</td>\n",
       "      <td>0.417396</td>\n",
       "      <td>0.742000</td>\n",
       "      <td>0.865707</td>\n",
       "      <td>0.335370</td>\n",
       "      <td>2.048923</td>\n",
       "      <td>-0.784050</td>\n",
       "      <td>-1.364779</td>\n",
       "      <td>-0.927087</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>0.143909</td>\n",
       "      <td>0.146218</td>\n",
       "      <td>0.146692</td>\n",
       "      <td>-1.601094</td>\n",
       "      <td>0.060779</td>\n",
       "      <td>0.522951</td>\n",
       "      <td>2.445150</td>\n",
       "      <td>-0.709292</td>\n",
       "      <td>1.639438</td>\n",
       "      <td>-1.330495</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9372</th>\n",
       "      <td>-0.686623</td>\n",
       "      <td>-1.211837</td>\n",
       "      <td>1.069371</td>\n",
       "      <td>-1.356219</td>\n",
       "      <td>-1.286132</td>\n",
       "      <td>-0.697720</td>\n",
       "      <td>0.115574</td>\n",
       "      <td>-0.559375</td>\n",
       "      <td>-1.887478</td>\n",
       "      <td>-1.982212</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7291</th>\n",
       "      <td>1.311047</td>\n",
       "      <td>-0.893888</td>\n",
       "      <td>1.069276</td>\n",
       "      <td>1.142341</td>\n",
       "      <td>0.155184</td>\n",
       "      <td>-0.479877</td>\n",
       "      <td>-1.275557</td>\n",
       "      <td>0.250859</td>\n",
       "      <td>-1.807859</td>\n",
       "      <td>2.170328</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>1.672363</td>\n",
       "      <td>-0.131861</td>\n",
       "      <td>1.355230</td>\n",
       "      <td>1.459562</td>\n",
       "      <td>-0.469457</td>\n",
       "      <td>-0.376764</td>\n",
       "      <td>-2.754493</td>\n",
       "      <td>0.916328</td>\n",
       "      <td>0.464703</td>\n",
       "      <td>-0.647731</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293</th>\n",
       "      <td>-0.472197</td>\n",
       "      <td>1.765242</td>\n",
       "      <td>-0.043818</td>\n",
       "      <td>0.665194</td>\n",
       "      <td>-0.106228</td>\n",
       "      <td>-0.013310</td>\n",
       "      <td>0.923962</td>\n",
       "      <td>0.177422</td>\n",
       "      <td>-1.919143</td>\n",
       "      <td>-0.145779</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>-0.092618</td>\n",
       "      <td>0.293755</td>\n",
       "      <td>2.562334</td>\n",
       "      <td>0.081724</td>\n",
       "      <td>-1.003581</td>\n",
       "      <td>1.441085</td>\n",
       "      <td>0.609717</td>\n",
       "      <td>-1.081265</td>\n",
       "      <td>-2.345868</td>\n",
       "      <td>0.463253</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "1121  0.735197  0.712926  0.677537  0.446614  0.447349 -0.597103 -1.025037   \n",
       "2877 -0.338972 -1.593443  0.584711 -0.310341  0.204547  1.566984  0.813121   \n",
       "1785 -1.910418  2.056198  1.126950  0.831595 -2.170040  0.654610 -1.919194   \n",
       "9806  0.470405  0.425514  0.417396  0.742000  0.865707  0.335370  2.048923   \n",
       "2232  0.143909  0.146218  0.146692 -1.601094  0.060779  0.522951  2.445150   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9372 -0.686623 -1.211837  1.069371 -1.356219 -1.286132 -0.697720  0.115574   \n",
       "7291  1.311047 -0.893888  1.069276  1.142341  0.155184 -0.479877 -1.275557   \n",
       "1344  1.672363 -0.131861  1.355230  1.459562 -0.469457 -0.376764 -2.754493   \n",
       "7293 -0.472197  1.765242 -0.043818  0.665194 -0.106228 -0.013310  0.923962   \n",
       "1289 -0.092618  0.293755  2.562334  0.081724 -1.003581  1.441085  0.609717   \n",
       "\n",
       "             7         8         9 10_imputed  \n",
       "1121 -1.020038 -1.814596 -0.194096       -1.0  \n",
       "2877 -0.818627  0.449865  1.788736        NaN  \n",
       "1785 -2.352304 -1.861600 -0.765301        1.0  \n",
       "9806 -0.784050 -1.364779 -0.927087       -1.0  \n",
       "2232 -0.709292  1.639438 -1.330495        1.0  \n",
       "...        ...       ...       ...        ...  \n",
       "9372 -0.559375 -1.887478 -1.982212        1.0  \n",
       "7291  0.250859 -1.807859  2.170328        1.0  \n",
       "1344  0.916328  0.464703 -0.647731        1.0  \n",
       "7293  0.177422 -1.919143 -0.145779       -1.0  \n",
       "1289 -1.081265 -2.345868  0.463253        1.0  \n",
       "\n",
       "[2000 rows x 11 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = X.columns[:-1]\n",
    "xxx = df_test.copy(deep=True)\n",
    "# xxx[label] = ''\n",
    "imputed = imputer.predict(xxx[features], precision_threshold=.9, inplace=True)\n",
    "imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22342025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     901\n",
       "-1.0    887\n",
       "        212\n",
       "Name: 10_imputed, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed['10_imputed'].fillna('').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19ac2f5b-bb56-4251-bb5a-ca0ad163dc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.00      0.00      0.00         0\n",
      "        -1.0       0.89      0.80      0.84       991\n",
      "         1.0       0.88      0.79      0.83      1009\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.59      0.53      0.56      2000\n",
      "weighted avg       0.89      0.79      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test[label],imputed[label+\"_imputed\"].fillna(\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2afc222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-1.0': {'precisions': array([0.58625954, 0.58562691, 0.58652374, 0.58742331, 0.58832565,\n",
       "         0.58923077, 0.59013867, 0.59104938, 0.59196291, 0.59287926,\n",
       "         0.59379845, 0.5947205 , 0.59564541, 0.59657321, 0.5975039 ,\n",
       "         0.5984375 , 0.59937402, 0.60031348, 0.60125589, 0.60220126,\n",
       "         0.60314961, 0.60410095, 0.60505529, 0.60601266, 0.60697306,\n",
       "         0.60793651, 0.60890302, 0.60987261, 0.6108453 , 0.61182109,\n",
       "         0.6128    , 0.61378205, 0.61476726, 0.61575563, 0.61674718,\n",
       "         0.61774194, 0.6187399 , 0.6197411 , 0.62074554, 0.62175325,\n",
       "         0.62276423, 0.6237785 , 0.62479608, 0.62581699, 0.62684124,\n",
       "         0.62622951, 0.6272578 , 0.62828947, 0.62932455, 0.63036304,\n",
       "         0.63140496, 0.63245033, 0.63349917, 0.6345515 , 0.63560732,\n",
       "         0.63666667, 0.63772955, 0.63879599, 0.639866  , 0.6409396 ,\n",
       "         0.64201681, 0.64309764, 0.64418212, 0.64527027, 0.6463621 ,\n",
       "         0.64745763, 0.64855688, 0.64965986, 0.65076661, 0.65187713,\n",
       "         0.65299145, 0.65410959, 0.6535163 , 0.65463918, 0.65576592,\n",
       "         0.65689655, 0.65630397, 0.65743945, 0.65857886, 0.65972222,\n",
       "         0.66086957, 0.66202091, 0.66317627, 0.66433566, 0.66549912,\n",
       "         0.66666667, 0.66783831, 0.66725352, 0.66843034, 0.66961131,\n",
       "         0.67079646, 0.67198582, 0.6731794 , 0.67437722, 0.67557932,\n",
       "         0.67678571, 0.67799642, 0.67921147, 0.68043088, 0.68165468,\n",
       "         0.68288288, 0.68411552, 0.68535262, 0.6865942 , 0.68784029,\n",
       "         0.68909091, 0.68852459, 0.68978102, 0.69104205, 0.69230769,\n",
       "         0.69357798, 0.69485294, 0.6961326 , 0.69557196, 0.69685767,\n",
       "         0.69814815, 0.69944341, 0.69888476, 0.70018622, 0.70149254,\n",
       "         0.70093458, 0.70224719, 0.70356473, 0.70488722, 0.70621469,\n",
       "         0.70754717, 0.70888469, 0.71022727, 0.71157495, 0.71292776,\n",
       "         0.71238095, 0.71374046, 0.71510516, 0.7164751 , 0.71785029,\n",
       "         0.71923077, 0.72061657, 0.72200772, 0.72147002, 0.72286822,\n",
       "         0.72427184, 0.72568093, 0.72709552, 0.72851562, 0.72994129,\n",
       "         0.73137255, 0.73084479, 0.73228346, 0.73372781, 0.73517787,\n",
       "         0.73663366, 0.73809524, 0.73956262, 0.74103586, 0.74251497,\n",
       "         0.744     , 0.74549098, 0.74698795, 0.74849095, 0.75      ,\n",
       "         0.75151515, 0.75303644, 0.75456389, 0.75609756, 0.75560081,\n",
       "         0.75510204, 0.75460123, 0.75614754, 0.75564682, 0.75514403,\n",
       "         0.75463918, 0.75413223, 0.75569358, 0.75726141, 0.75883576,\n",
       "         0.76041667, 0.75991649, 0.75941423, 0.76100629, 0.7605042 ,\n",
       "         0.76210526, 0.76160338, 0.76321353, 0.76483051, 0.76645435,\n",
       "         0.76808511, 0.76972281, 0.77136752, 0.77301927, 0.77467811,\n",
       "         0.77419355, 0.7737069 , 0.77321814, 0.77489177, 0.77657267,\n",
       "         0.77608696, 0.77559913, 0.77729258, 0.77899344, 0.78070175,\n",
       "         0.78241758, 0.78414097, 0.78587196, 0.78539823, 0.78492239,\n",
       "         0.78666667, 0.78619154, 0.78794643, 0.78747204, 0.78699552,\n",
       "         0.78876404, 0.79054054, 0.79232506, 0.79411765, 0.79591837,\n",
       "         0.79545455, 0.79498861, 0.79680365, 0.798627  , 0.80045872,\n",
       "         0.8       , 0.80184332, 0.80369515, 0.80555556, 0.80510441,\n",
       "         0.80697674, 0.80885781, 0.80841121, 0.81030445, 0.81220657,\n",
       "         0.81411765, 0.81603774, 0.8179669 , 0.81753555, 0.81947743,\n",
       "         0.82142857, 0.82100239, 0.82296651, 0.82254197, 0.82451923,\n",
       "         0.82650602, 0.82608696, 0.82808717, 0.8276699 , 0.8296837 ,\n",
       "         0.82926829, 0.83129584, 0.83088235, 0.83046683, 0.83004926,\n",
       "         0.82962963, 0.83168317, 0.83126551, 0.83084577, 0.83042394,\n",
       "         0.8325    , 0.8320802 , 0.83417085, 0.83627204, 0.83838384,\n",
       "         0.84050633, 0.84263959, 0.84478372, 0.84438776, 0.84654731,\n",
       "         0.84871795, 0.85089974, 0.85309278, 0.85529716, 0.85751295,\n",
       "         0.85714286, 0.85677083, 0.85639687, 0.85602094, 0.85826772,\n",
       "         0.86052632, 0.86279683, 0.86507937, 0.86472149, 0.8643617 ,\n",
       "         0.864     , 0.86631016, 0.86595174, 0.8655914 , 0.86522911,\n",
       "         0.86756757, 0.8699187 , 0.87228261, 0.8746594 , 0.87431694,\n",
       "         0.8739726 , 0.87637363, 0.87878788, 0.87845304, 0.88088643,\n",
       "         0.88055556, 0.88022284, 0.88268156, 0.88515406, 0.88483146,\n",
       "         0.88732394, 0.88700565, 0.88668555, 0.88920455, 0.88888889,\n",
       "         0.89142857, 0.89398281, 0.89367816, 0.89337176, 0.89595376,\n",
       "         0.89855072, 0.90116279, 0.90087464, 0.9005848 , 0.90029326,\n",
       "         0.9       , 0.89970501, 0.90236686, 0.90207715, 0.9047619 ,\n",
       "         0.90447761, 0.90419162, 0.9039039 , 0.90361446, 0.90332326,\n",
       "         0.90606061, 0.90881459, 0.91158537, 0.91131498, 0.91104294,\n",
       "         0.91076923, 0.91049383, 0.91021672, 0.90993789, 0.90965732,\n",
       "         0.9125    , 0.91222571, 0.91194969, 0.9148265 , 0.91455696,\n",
       "         0.91746032, 0.92038217, 0.92332268, 0.92307692, 0.92282958,\n",
       "         0.92258065, 0.9223301 , 0.92207792, 0.92508143, 0.9248366 ,\n",
       "         0.92786885, 0.92763158, 0.92739274, 0.92715232, 0.93023256,\n",
       "         0.93      , 0.92976589, 0.9295302 , 0.92929293, 0.92905405,\n",
       "         0.93220339, 0.93197279, 0.93174061, 0.93493151, 0.9347079 ,\n",
       "         0.93448276, 0.93425606, 0.93402778, 0.93379791, 0.93356643,\n",
       "         0.93333333, 0.93309859, 0.93286219, 0.93262411, 0.93238434,\n",
       "         0.93571429, 0.9390681 , 0.93884892, 0.93862816, 0.9384058 ,\n",
       "         0.93818182, 0.9379562 , 0.93772894, 0.9375    , 0.94095941,\n",
       "         0.94074074, 0.94423792, 0.94402985, 0.94382022, 0.94360902,\n",
       "         0.94339623, 0.94318182, 0.94676806, 0.94656489, 0.94636015,\n",
       "         0.94615385, 0.94594595, 0.94573643, 0.94552529, 0.9453125 ,\n",
       "         0.94509804, 0.94488189, 0.94466403, 0.94444444, 0.94422311,\n",
       "         0.948     , 0.95180723, 0.9516129 , 0.951417  , 0.95121951,\n",
       "         0.95102041, 0.95491803, 0.95473251, 0.95454545, 0.95435685,\n",
       "         0.95833333, 0.958159  , 0.95798319, 0.95780591, 0.95762712,\n",
       "         0.95744681, 0.95726496, 0.96137339, 0.9612069 , 0.96103896,\n",
       "         0.96086957, 0.96069869, 0.96052632, 0.96035242, 0.96460177,\n",
       "         0.96444444, 0.96428571, 0.96412556, 0.96396396, 0.96832579,\n",
       "         0.96818182, 0.96803653, 0.96788991, 0.96774194, 0.97222222,\n",
       "         0.97674419, 0.97663551, 0.97652582, 0.97641509, 0.97630332,\n",
       "         0.97619048, 0.97607656, 0.97596154, 0.97584541, 0.97572816,\n",
       "         0.97560976, 0.9754902 , 0.97536946, 0.97524752, 0.97512438,\n",
       "         0.975     , 0.97487437, 0.97474747, 0.97461929, 0.9744898 ,\n",
       "         0.97435897, 0.9742268 , 0.97409326, 0.97395833, 0.97382199,\n",
       "         0.97368421, 0.97354497, 0.97340426, 0.97326203, 0.97311828,\n",
       "         0.97297297, 0.97282609, 0.9726776 , 0.97252747, 0.97237569,\n",
       "         0.97222222, 0.97765363, 0.97752809, 0.97740113, 0.97727273,\n",
       "         0.97714286, 0.97701149, 0.97687861, 0.97674419, 0.97660819,\n",
       "         0.98235294, 0.98224852, 0.98214286, 0.98203593, 0.98192771,\n",
       "         0.98181818, 0.98170732, 0.98159509, 0.98148148, 0.98136646,\n",
       "         0.98125   , 0.98113208, 0.98734177, 0.98726115, 0.98717949,\n",
       "         0.98709677, 0.98701299, 0.9869281 , 0.98684211, 0.99337748,\n",
       "         0.99333333, 0.99328859, 0.99324324, 0.99319728, 0.99315068,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        ]),\n",
       "  'thresholds': array([0.19493222, 0.19864571, 0.19902307, 0.19934452, 0.1999141 ,\n",
       "         0.20003104, 0.20027626, 0.20055437, 0.20085371, 0.20140338,\n",
       "         0.20390868, 0.20515597, 0.20694119, 0.2073952 , 0.20761871,\n",
       "         0.20785904, 0.20856094, 0.21084821, 0.21099555, 0.2113865 ,\n",
       "         0.21224231, 0.21275538, 0.21353197, 0.21456599, 0.21553272,\n",
       "         0.21558607, 0.22010434, 0.22329593, 0.22403747, 0.22472334,\n",
       "         0.22515285, 0.22658288, 0.22752142, 0.22913361, 0.23562187,\n",
       "         0.23606777, 0.23637307, 0.23867893, 0.24007654, 0.24056995,\n",
       "         0.24099529, 0.24103791, 0.2427913 , 0.24347329, 0.24547994,\n",
       "         0.24558675, 0.2460289 , 0.24773633, 0.24856538, 0.24880981,\n",
       "         0.25023115, 0.25042355, 0.25093114, 0.25142431, 0.25227892,\n",
       "         0.25305057, 0.25402737, 0.25465697, 0.25470114, 0.255193  ,\n",
       "         0.25530696, 0.2580291 , 0.25969583, 0.25999749, 0.26025701,\n",
       "         0.26043487, 0.26111227, 0.2618196 , 0.26349854, 0.26743889,\n",
       "         0.26800489, 0.26805073, 0.2701776 , 0.27207232, 0.27305973,\n",
       "         0.27337813, 0.27425456, 0.27812481, 0.2781468 , 0.27875179,\n",
       "         0.27980042, 0.28124869, 0.28188831, 0.2827853 , 0.28390288,\n",
       "         0.2839241 , 0.28531158, 0.28540844, 0.28628135, 0.28722537,\n",
       "         0.28802788, 0.28812039, 0.29336321, 0.2946611 , 0.29558915,\n",
       "         0.29598486, 0.29845273, 0.29998374, 0.30053246, 0.30101192,\n",
       "         0.30230534, 0.30300653, 0.30344164, 0.30410004, 0.30442786,\n",
       "         0.30584681, 0.30799258, 0.30870402, 0.31016326, 0.31098056,\n",
       "         0.31131029, 0.31173623, 0.31181395, 0.31239831, 0.31303179,\n",
       "         0.31374669, 0.3149724 , 0.31533146, 0.31578255, 0.31735218,\n",
       "         0.31956023, 0.32306886, 0.32384753, 0.32520175, 0.32522333,\n",
       "         0.32557064, 0.32666457, 0.32819772, 0.33062547, 0.33172679,\n",
       "         0.3319633 , 0.33315265, 0.33377445, 0.33515894, 0.3353343 ,\n",
       "         0.33534241, 0.3381623 , 0.33830035, 0.33913112, 0.34034544,\n",
       "         0.34201431, 0.34219885, 0.3434968 , 0.34350091, 0.34444427,\n",
       "         0.34492081, 0.34563994, 0.346946  , 0.34843105, 0.34924376,\n",
       "         0.35143507, 0.35177284, 0.35200524, 0.35239285, 0.35347807,\n",
       "         0.35439885, 0.35802215, 0.35824335, 0.36283278, 0.36313885,\n",
       "         0.36440575, 0.36514318, 0.36546874, 0.36560506, 0.36627305,\n",
       "         0.36775517, 0.36802429, 0.37094271, 0.37221456, 0.37238795,\n",
       "         0.37332308, 0.37369549, 0.37649578, 0.37727797, 0.37798417,\n",
       "         0.37833023, 0.37915266, 0.38446343, 0.38561815, 0.38582647,\n",
       "         0.3865478 , 0.38743466, 0.39269751, 0.39430213, 0.39455628,\n",
       "         0.39614141, 0.39938074, 0.40101373, 0.40154469, 0.40171349,\n",
       "         0.40197164, 0.40656471, 0.40680778, 0.40822989, 0.40947944,\n",
       "         0.41062182, 0.41082448, 0.41349375, 0.41440064, 0.41864425,\n",
       "         0.41944176, 0.41945708, 0.42148304, 0.42151213, 0.42205322,\n",
       "         0.42218691, 0.42311096, 0.42541975, 0.42617929, 0.43081903,\n",
       "         0.43143141, 0.43361294, 0.43411493, 0.43450856, 0.43587822,\n",
       "         0.43603659, 0.43727028, 0.43786395, 0.43802929, 0.43943346,\n",
       "         0.43997371, 0.44002855, 0.44242752, 0.44296157, 0.44444501,\n",
       "         0.4460634 , 0.44988811, 0.45221823, 0.4544273 , 0.45458102,\n",
       "         0.45471227, 0.4547168 , 0.45839214, 0.46205699, 0.46416485,\n",
       "         0.46578038, 0.46629918, 0.46716332, 0.46748978, 0.4689678 ,\n",
       "         0.47052729, 0.47075319, 0.4719491 , 0.47314584, 0.47382951,\n",
       "         0.47550422, 0.47615838, 0.48049402, 0.48126256, 0.48271787,\n",
       "         0.48308331, 0.48405755, 0.48477209, 0.48551542, 0.48558694,\n",
       "         0.48632634, 0.48685038, 0.48689407, 0.48696375, 0.48857695,\n",
       "         0.48877501, 0.48879254, 0.48925984, 0.48935527, 0.49013776,\n",
       "         0.49338603, 0.4950487 , 0.49659705, 0.49666619, 0.49727368,\n",
       "         0.49993753, 0.50046825, 0.50097322, 0.50146621, 0.50148225,\n",
       "         0.50149518, 0.50479144, 0.50575936, 0.50610209, 0.51052266,\n",
       "         0.51126003, 0.51303363, 0.51425862, 0.51511312, 0.51523954,\n",
       "         0.51724356, 0.51742685, 0.51963669, 0.52056825, 0.52161473,\n",
       "         0.52252358, 0.52434623, 0.52542615, 0.52836525, 0.52903485,\n",
       "         0.53130704, 0.53159308, 0.53426659, 0.53430432, 0.53643304,\n",
       "         0.5368979 , 0.53759372, 0.53978473, 0.5400157 , 0.54111373,\n",
       "         0.54263061, 0.54292297, 0.54741663, 0.55289972, 0.554676  ,\n",
       "         0.55607158, 0.55665886, 0.55760658, 0.55794567, 0.55853945,\n",
       "         0.55920368, 0.56067318, 0.56490219, 0.56537062, 0.56749487,\n",
       "         0.5687719 , 0.56923544, 0.57134509, 0.57149506, 0.572348  ,\n",
       "         0.57297909, 0.57317924, 0.5748539 , 0.57512546, 0.57563108,\n",
       "         0.57616496, 0.57758051, 0.57818246, 0.57897532, 0.58300638,\n",
       "         0.58517069, 0.5878709 , 0.58835042, 0.58998704, 0.59020293,\n",
       "         0.59275877, 0.5933007 , 0.5944804 , 0.59469563, 0.5962466 ,\n",
       "         0.59631163, 0.59711486, 0.59850383, 0.60069823, 0.60099125,\n",
       "         0.60104495, 0.60191429, 0.60334766, 0.6044184 , 0.60469681,\n",
       "         0.60571784, 0.60838735, 0.60949874, 0.61091691, 0.61382258,\n",
       "         0.61436254, 0.61553884, 0.61657178, 0.61776698, 0.61960948,\n",
       "         0.621095  , 0.62142473, 0.62297738, 0.62328804, 0.62344712,\n",
       "         0.62429619, 0.62477881, 0.62633169, 0.62784863, 0.62846911,\n",
       "         0.63631111, 0.64278734, 0.64306056, 0.64318615, 0.64602244,\n",
       "         0.64685678, 0.64735889, 0.64740336, 0.64753175, 0.65178776,\n",
       "         0.65271211, 0.65901738, 0.65998131, 0.66032481, 0.66301674,\n",
       "         0.66401613, 0.66411543, 0.66726518, 0.66797638, 0.66806608,\n",
       "         0.668782  , 0.66945428, 0.6711337 , 0.6712333 , 0.67198157,\n",
       "         0.67445117, 0.67460978, 0.67504019, 0.67504352, 0.67555505,\n",
       "         0.67734706, 0.67911011, 0.67966294, 0.6799835 , 0.68259728,\n",
       "         0.68270022, 0.68430084, 0.68465328, 0.68595231, 0.68610239,\n",
       "         0.68618464, 0.68682849, 0.68697059, 0.68723392, 0.68756723,\n",
       "         0.68859482, 0.68882883, 0.68949783, 0.68996805, 0.69038725,\n",
       "         0.69362122, 0.69442552, 0.69449842, 0.70144796, 0.70271397,\n",
       "         0.70315558, 0.70315748, 0.7035991 , 0.70425737, 0.70471281,\n",
       "         0.70609748, 0.7062341 , 0.70741594, 0.70758951, 0.70975381,\n",
       "         0.71196806, 0.71258354, 0.7130869 , 0.71385682, 0.72274739,\n",
       "         0.72536033, 0.72668332, 0.72718108, 0.7282213 , 0.72932613,\n",
       "         0.73069537, 0.73443556, 0.73627651, 0.73642099, 0.73642421,\n",
       "         0.73834848, 0.73986334, 0.74007797, 0.74086136, 0.74305242,\n",
       "         0.74436522, 0.74451256, 0.74601418, 0.7468152 , 0.74695957,\n",
       "         0.74749148, 0.74845874, 0.74945629, 0.751068  , 0.75221252,\n",
       "         0.75373244, 0.75399148, 0.75425237, 0.75547969, 0.75796205,\n",
       "         0.75862354, 0.75981241, 0.75992739, 0.75992894, 0.7610361 ,\n",
       "         0.76189077, 0.76220214, 0.76296115, 0.76362938, 0.7636829 ,\n",
       "         0.76575917, 0.76591086, 0.7662816 , 0.76716715, 0.76716918,\n",
       "         0.76770079, 0.76952893, 0.77066535, 0.77192193, 0.7754482 ,\n",
       "         0.77677476, 0.77682012, 0.77822113, 0.78066927, 0.78246921,\n",
       "         0.78485203, 0.78519177, 0.78521228, 0.78621823, 0.78670382,\n",
       "         0.78721946, 0.78795403, 0.78841639, 0.79383874, 0.79500371,\n",
       "         0.79537326, 0.7956394 , 0.79759061, 0.7984786 , 0.79852509,\n",
       "         0.80288166, 0.80376184, 0.80462152, 0.80483544, 0.80566609,\n",
       "         0.80583286, 0.80605716, 0.80788279, 0.8094424 , 0.81284231,\n",
       "         0.81318104, 0.8137157 , 0.81607878, 0.81839693, 0.8184523 ,\n",
       "         0.81871152, 0.81920022, 0.81964332, 0.81984341, 0.81994092,\n",
       "         0.82045102, 0.82251596, 0.82398152, 0.82583529, 0.82630718,\n",
       "         0.82652414, 0.82733923, 0.82924831, 0.82972515, 0.83017802,\n",
       "         0.83149087, 0.83170331, 0.83486092, 0.83515394, 0.83753991,\n",
       "         0.84006262, 0.84097993, 0.84122497, 0.84245938, 0.84359521,\n",
       "         0.84468532, 0.84755445, 0.84831625, 0.84845448, 0.84905016,\n",
       "         0.8508327 , 0.85157573, 0.85484344, 0.85698676, 0.86046064,\n",
       "         0.86070144, 0.86089486, 0.86168128, 0.86278582, 0.86364478,\n",
       "         0.86406088, 0.86722934, 0.86747545, 0.86850458, 0.86908746,\n",
       "         0.87041199, 0.87145317, 0.87187314, 0.87227654, 0.8728264 ,\n",
       "         0.87297571, 0.87677979, 0.87912941, 0.88009369, 0.88237709,\n",
       "         0.88357043, 0.88453883, 0.88504797, 0.8852818 , 0.88531041,\n",
       "         0.88589501, 0.88700509, 0.88743818, 0.888758  , 0.89045691,\n",
       "         0.8905791 , 0.89158142, 0.89257324, 0.89400059, 0.89425969,\n",
       "         0.89499271, 0.89646626, 0.89744866, 0.89977407, 0.90176815,\n",
       "         0.90368402, 0.9038204 , 0.90407109, 0.90436888, 0.90438211,\n",
       "         0.90494251, 0.90499586, 0.90578651, 0.9128772 , 0.91306967,\n",
       "         0.91389179, 0.91399074, 0.91507411, 0.91555452, 0.91849887,\n",
       "         0.91959494, 0.91978931, 0.919972  , 0.9210434 , 0.92319727,\n",
       "         0.92346442, 0.92449409, 0.92479527, 0.92481393, 0.92798978,\n",
       "         0.92824823, 0.92883444, 0.92909878, 0.9314456 , 0.93791068,\n",
       "         0.93806386, 0.93924999, 0.93984538, 0.94019049, 0.94063306,\n",
       "         0.94401252, 0.94461358, 0.94819409, 0.95197654, 0.95343453,\n",
       "         0.95587951, 0.95843327, 0.95875418, 0.96202415, 0.96454644,\n",
       "         0.966717  , 0.96868718, 0.97451645, 0.97499043, 0.97671074])},\n",
       " '1.0': {'precisions': array([0.6351145 , 0.63455657, 0.63552833, 0.63650307, 0.6374808 ,\n",
       "         0.63846154, 0.6394453 , 0.63888889, 0.63987635, 0.64086687,\n",
       "         0.64186047, 0.64285714, 0.64385692, 0.64485981, 0.64430577,\n",
       "         0.6453125 , 0.64632238, 0.64733542, 0.64835165, 0.64937107,\n",
       "         0.6503937 , 0.65141956, 0.65244866, 0.65348101, 0.65451664,\n",
       "         0.65555556, 0.65500795, 0.65605096, 0.65709729, 0.65814696,\n",
       "         0.6592    , 0.66025641, 0.66131621, 0.66237942, 0.66344605,\n",
       "         0.66290323, 0.66397415, 0.66504854, 0.66612642, 0.66720779,\n",
       "         0.66829268, 0.66938111, 0.67047308, 0.67156863, 0.67266776,\n",
       "         0.67377049, 0.67487685, 0.67598684, 0.67710049, 0.67821782,\n",
       "         0.67933884, 0.68046358, 0.68159204, 0.68272425, 0.68386023,\n",
       "         0.685     , 0.68614357, 0.68729097, 0.68844221, 0.68959732,\n",
       "         0.6907563 , 0.69191919, 0.693086  , 0.69425676, 0.69543147,\n",
       "         0.69661017, 0.69779287, 0.69897959, 0.70017036, 0.70136519,\n",
       "         0.7025641 , 0.70205479, 0.70154374, 0.70274914, 0.70395869,\n",
       "         0.70517241, 0.70639033, 0.70588235, 0.70710572, 0.70833333,\n",
       "         0.70956522, 0.71080139, 0.71029668, 0.71153846, 0.71278459,\n",
       "         0.71403509, 0.71528998, 0.7165493 , 0.71781305, 0.71731449,\n",
       "         0.71858407, 0.71985816, 0.72113677, 0.72241993, 0.72370766,\n",
       "         0.725     , 0.72450805, 0.72580645, 0.72710952, 0.72841727,\n",
       "         0.72792793, 0.72924188, 0.73056058, 0.73188406, 0.73321234,\n",
       "         0.73272727, 0.73224044, 0.73357664, 0.73491773, 0.73626374,\n",
       "         0.73761468, 0.73897059, 0.74033149, 0.74169742, 0.74306839,\n",
       "         0.74444444, 0.7458256 , 0.7472119 , 0.74860335, 0.74813433,\n",
       "         0.74953271, 0.75093633, 0.75234522, 0.7537594 , 0.75517891,\n",
       "         0.75471698, 0.75614367, 0.75568182, 0.75711575, 0.75855513,\n",
       "         0.76      , 0.76145038, 0.76290631, 0.76436782, 0.76583493,\n",
       "         0.76538462, 0.76493256, 0.76640927, 0.76789168, 0.76937984,\n",
       "         0.77087379, 0.77237354, 0.77387914, 0.77539062, 0.77690802,\n",
       "         0.77843137, 0.77996071, 0.78149606, 0.78106509, 0.7826087 ,\n",
       "         0.78415842, 0.78373016, 0.78528827, 0.78685259, 0.78842315,\n",
       "         0.79      , 0.79158317, 0.79116466, 0.79275654, 0.79435484,\n",
       "         0.7959596 , 0.79554656, 0.79716024, 0.79674797, 0.79837067,\n",
       "         0.8       , 0.80163599, 0.80327869, 0.80492813, 0.80452675,\n",
       "         0.80412371, 0.80371901, 0.80538302, 0.80497925, 0.80665281,\n",
       "         0.80833333, 0.80793319, 0.80962343, 0.81132075, 0.81302521,\n",
       "         0.81473684, 0.8164557 , 0.81818182, 0.81991525, 0.81953291,\n",
       "         0.81914894, 0.81876333, 0.82051282, 0.82226981, 0.82403433,\n",
       "         0.82580645, 0.82758621, 0.82721382, 0.82900433, 0.82863341,\n",
       "         0.83043478, 0.83224401, 0.83406114, 0.83588621, 0.8377193 ,\n",
       "         0.83736264, 0.83700441, 0.83664459, 0.83849558, 0.84035477,\n",
       "         0.84      , 0.83964365, 0.84151786, 0.84116331, 0.84304933,\n",
       "         0.84494382, 0.84459459, 0.84650113, 0.84615385, 0.84580499,\n",
       "         0.84772727, 0.84965831, 0.84931507, 0.85125858, 0.85091743,\n",
       "         0.85057471, 0.85253456, 0.85450346, 0.85416667, 0.85382831,\n",
       "         0.85348837, 0.85314685, 0.85514019, 0.85714286, 0.85915493,\n",
       "         0.85882353, 0.86084906, 0.86288416, 0.86492891, 0.86460808,\n",
       "         0.86428571, 0.86396181, 0.86363636, 0.86570743, 0.86778846,\n",
       "         0.86987952, 0.87198068, 0.8716707 , 0.87135922, 0.87104623,\n",
       "         0.87073171, 0.87041565, 0.87009804, 0.87223587, 0.87192118,\n",
       "         0.87160494, 0.87128713, 0.87096774, 0.87064677, 0.87032419,\n",
       "         0.8725    , 0.87218045, 0.87437186, 0.87657431, 0.87878788,\n",
       "         0.87848101, 0.88071066, 0.88295165, 0.88520408, 0.88746803,\n",
       "         0.88717949, 0.88946015, 0.88917526, 0.89147287, 0.89119171,\n",
       "         0.89350649, 0.89322917, 0.89295039, 0.89528796, 0.89501312,\n",
       "         0.89736842, 0.89709763, 0.8968254 , 0.89920424, 0.89893617,\n",
       "         0.89866667, 0.89839572, 0.89812332, 0.89784946, 0.90026954,\n",
       "         0.9       , 0.899729  , 0.90217391, 0.90190736, 0.90163934,\n",
       "         0.90136986, 0.90384615, 0.90358127, 0.90331492, 0.90304709,\n",
       "         0.90555556, 0.90807799, 0.90782123, 0.90756303, 0.90730337,\n",
       "         0.90704225, 0.90677966, 0.90934844, 0.91193182, 0.91168091,\n",
       "         0.91428571, 0.91404011, 0.91666667, 0.91930836, 0.91907514,\n",
       "         0.91884058, 0.91860465, 0.91836735, 0.91812865, 0.91788856,\n",
       "         0.92058824, 0.92330383, 0.92307692, 0.92284866, 0.92559524,\n",
       "         0.92835821, 0.93113772, 0.93093093, 0.93072289, 0.9305136 ,\n",
       "         0.93030303, 0.93009119, 0.92987805, 0.92966361, 0.92944785,\n",
       "         0.93230769, 0.93209877, 0.93498452, 0.93478261, 0.9376947 ,\n",
       "         0.940625  , 0.94043887, 0.94025157, 0.94006309, 0.93987342,\n",
       "         0.94285714, 0.94585987, 0.94888179, 0.95192308, 0.95176849,\n",
       "         0.95483871, 0.9579288 , 0.96103896, 0.96091205, 0.96078431,\n",
       "         0.96065574, 0.96052632, 0.96039604, 0.9602649 , 0.96013289,\n",
       "         0.96      , 0.95986622, 0.95973154, 0.95959596, 0.95945946,\n",
       "         0.95932203, 0.95918367, 0.95904437, 0.95890411, 0.95876289,\n",
       "         0.96206897, 0.96193772, 0.96180556, 0.96167247, 0.96153846,\n",
       "         0.96140351, 0.96126761, 0.96113074, 0.96453901, 0.96441281,\n",
       "         0.96428571, 0.96415771, 0.96402878, 0.96389892, 0.96376812,\n",
       "         0.96363636, 0.96715328, 0.96703297, 0.96691176, 0.96678967,\n",
       "         0.96666667, 0.96654275, 0.96641791, 0.96629213, 0.96616541,\n",
       "         0.96603774, 0.96969697, 0.96958175, 0.96946565, 0.97318008,\n",
       "         0.97307692, 0.97297297, 0.97286822, 0.9766537 , 0.9765625 ,\n",
       "         0.97647059, 0.97637795, 0.97628458, 0.97619048, 0.97609562,\n",
       "         0.98      , 0.97991968, 0.97983871, 0.97975709, 0.9796748 ,\n",
       "         0.97959184, 0.9795082 , 0.97942387, 0.97933884, 0.97925311,\n",
       "         0.97916667, 0.9790795 , 0.9789916 , 0.97890295, 0.97881356,\n",
       "         0.9787234 , 0.97863248, 0.97854077, 0.97844828, 0.98268398,\n",
       "         0.9826087 , 0.98253275, 0.98245614, 0.98237885, 0.98230088,\n",
       "         0.98222222, 0.98214286, 0.98206278, 0.98198198, 0.98190045,\n",
       "         0.98636364, 0.98630137, 0.98623853, 0.98617512, 0.99074074,\n",
       "         0.99069767, 0.99065421, 0.99061033, 0.99056604, 0.99052133,\n",
       "         0.99047619, 0.99043062, 0.99038462, 0.99033816, 0.99029126,\n",
       "         0.9902439 , 0.99019608, 0.99014778, 0.99009901, 0.99004975,\n",
       "         0.99      , 0.98994975, 0.98989899, 0.98984772, 0.98979592,\n",
       "         0.98974359, 0.98969072, 0.98963731, 0.98958333, 0.9895288 ,\n",
       "         0.98947368, 0.99470899, 0.99468085, 0.99465241, 0.99462366,\n",
       "         0.99459459, 0.99456522, 0.99453552, 0.99450549, 0.99447514,\n",
       "         0.99444444, 0.99441341, 0.99438202, 0.99435028, 0.99431818,\n",
       "         0.99428571, 0.99425287, 0.99421965, 0.99418605, 0.99415205,\n",
       "         0.99411765, 0.99408284, 0.99404762, 0.99401198, 0.9939759 ,\n",
       "         0.99393939, 0.99390244, 0.99386503, 0.99382716, 0.99378882,\n",
       "         0.99375   , 0.99371069, 0.99367089, 0.99363057, 0.99358974,\n",
       "         0.99354839, 0.99350649, 0.99346405, 0.99342105, 0.99337748,\n",
       "         0.99333333, 0.99328859, 0.99324324, 0.99319728, 0.99315068,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        ]),\n",
       "  'thresholds': array([0.2049963 , 0.20616126, 0.21158364, 0.21204598, 0.21278054,\n",
       "         0.21329618, 0.21378177, 0.21478769, 0.21480823, 0.215148  ,\n",
       "         0.2175308 , 0.21933073, 0.2217789 , 0.22317988, 0.22322524,\n",
       "         0.22455177, 0.22807807, 0.22933465, 0.23047106, 0.23229924,\n",
       "         0.23283081, 0.23283285, 0.23371843, 0.23408917, 0.23424084,\n",
       "         0.2363171 , 0.23637064, 0.23703887, 0.23779789, 0.23810923,\n",
       "         0.23896389, 0.24007103, 0.24007258, 0.2401876 , 0.24137646,\n",
       "         0.24203797, 0.24452028, 0.24574761, 0.24600849, 0.24626756,\n",
       "         0.24778745, 0.24893197, 0.25054374, 0.25154129, 0.25250852,\n",
       "         0.25304043, 0.2531848 , 0.25398582, 0.25548747, 0.25563481,\n",
       "         0.25694758, 0.25913864, 0.25992206, 0.26013666, 0.26165152,\n",
       "         0.26357576, 0.26357898, 0.26372349, 0.26556441, 0.26930466,\n",
       "         0.27067384, 0.27177867, 0.27281892, 0.27331668, 0.27463967,\n",
       "         0.27725261, 0.28614315, 0.2869131 , 0.28741643, 0.28803191,\n",
       "         0.29024619, 0.29241049, 0.29258403, 0.29376587, 0.29390249,\n",
       "         0.29528719, 0.29574263, 0.29640093, 0.29684252, 0.29684442,\n",
       "         0.297286  , 0.29855207, 0.30550155, 0.30557448, 0.30637878,\n",
       "         0.30961272, 0.31003195, 0.31050217, 0.31117117, 0.31140518,\n",
       "         0.31243274, 0.31276608, 0.31302938, 0.31317151, 0.31381536,\n",
       "         0.31389758, 0.31404769, 0.31534672, 0.31569916, 0.31729978,\n",
       "         0.31740275, 0.32001647, 0.32033706, 0.32088989, 0.32265291,\n",
       "         0.32444495, 0.32495648, 0.32495981, 0.32539025, 0.32554883,\n",
       "         0.32801843, 0.3287667 , 0.3288663 , 0.33054572, 0.331218  ,\n",
       "         0.33193392, 0.33202362, 0.33273482, 0.33588457, 0.3359839 ,\n",
       "         0.33698326, 0.33967522, 0.34001869, 0.34098262, 0.34728786,\n",
       "         0.34821224, 0.35246828, 0.35259664, 0.35264111, 0.35314322,\n",
       "         0.35397753, 0.35681385, 0.35693941, 0.35721263, 0.36368889,\n",
       "         0.37153092, 0.3721514 , 0.37366831, 0.37522119, 0.37570378,\n",
       "         0.37655288, 0.37671196, 0.37702265, 0.37857527, 0.378905  ,\n",
       "         0.38039052, 0.38223302, 0.38342822, 0.38446116, 0.38563746,\n",
       "         0.38617745, 0.38908309, 0.39050123, 0.39161268, 0.39428216,\n",
       "         0.39530319, 0.39558157, 0.39665231, 0.39808571, 0.39895505,\n",
       "         0.39900872, 0.3993018 , 0.40149614, 0.40288514, 0.40368837,\n",
       "         0.4037534 , 0.40530437, 0.40551957, 0.40669933, 0.40724123,\n",
       "         0.4097971 , 0.41001299, 0.41164955, 0.4121291 , 0.41482931,\n",
       "         0.41699362, 0.42102468, 0.42181754, 0.42241949, 0.42383504,\n",
       "         0.42436892, 0.42487451, 0.42514613, 0.42682076, 0.42702091,\n",
       "         0.427652  , 0.42850497, 0.42865491, 0.43076456, 0.4312281 ,\n",
       "         0.43250513, 0.43462938, 0.43509778, 0.43932682, 0.44079632,\n",
       "         0.44146055, 0.44205433, 0.44239342, 0.44334114, 0.44392842,\n",
       "         0.445324  , 0.44710031, 0.45258337, 0.45707703, 0.45736939,\n",
       "         0.4588863 , 0.4599843 , 0.46021527, 0.46240628, 0.4631021 ,\n",
       "         0.46356696, 0.46569568, 0.46573341, 0.46840689, 0.46869296,\n",
       "         0.47096515, 0.47163475, 0.47457385, 0.4756538 , 0.47747642,\n",
       "         0.47838527, 0.47943172, 0.48036331, 0.48257315, 0.48275644,\n",
       "         0.48476046, 0.48488688, 0.48574138, 0.48696637, 0.48873997,\n",
       "         0.48947734, 0.49389794, 0.49424067, 0.49520856, 0.49850482,\n",
       "         0.49851778, 0.49853379, 0.49902678, 0.49953172, 0.50006247,\n",
       "         0.50272632, 0.50333381, 0.50340295, 0.5049513 , 0.50661397,\n",
       "         0.50986224, 0.51064473, 0.51074016, 0.51120746, 0.51122499,\n",
       "         0.51142305, 0.51303625, 0.51310593, 0.51314962, 0.51367366,\n",
       "         0.51441306, 0.51448458, 0.51522791, 0.51594245, 0.51691669,\n",
       "         0.51728213, 0.51873744, 0.51950598, 0.52384162, 0.52449578,\n",
       "         0.52617049, 0.52685416, 0.5280509 , 0.52924681, 0.52947271,\n",
       "         0.5310322 , 0.53251022, 0.53283668, 0.53370082, 0.53421962,\n",
       "         0.53583515, 0.53794301, 0.54160786, 0.5452832 , 0.54528773,\n",
       "         0.54541898, 0.5455727 , 0.54778177, 0.55011189, 0.5539366 ,\n",
       "         0.55555499, 0.55703843, 0.55757248, 0.55997145, 0.56002629,\n",
       "         0.56056654, 0.56197071, 0.56213605, 0.56272972, 0.56396341,\n",
       "         0.56412178, 0.56549144, 0.56588507, 0.56638706, 0.56856859,\n",
       "         0.56918097, 0.57382071, 0.57458025, 0.57688904, 0.57781309,\n",
       "         0.57794678, 0.57848787, 0.57851696, 0.58054292, 0.58055824,\n",
       "         0.58135575, 0.58559936, 0.58650625, 0.58917552, 0.58937818,\n",
       "         0.59052056, 0.59177011, 0.59319222, 0.59343529, 0.59802836,\n",
       "         0.59828651, 0.59845531, 0.59898627, 0.60061926, 0.60385859,\n",
       "         0.60544372, 0.60569787, 0.60730249, 0.61256534, 0.6134522 ,\n",
       "         0.61417353, 0.61438185, 0.61553657, 0.62084734, 0.62166977,\n",
       "         0.62201583, 0.62272203, 0.62350422, 0.62630451, 0.62667692,\n",
       "         0.62761205, 0.62778544, 0.62905729, 0.63197571, 0.63224483,\n",
       "         0.63372695, 0.63439494, 0.63453126, 0.63485682, 0.63559425,\n",
       "         0.63686115, 0.63716722, 0.64175665, 0.64197785, 0.64560115,\n",
       "         0.64652193, 0.64760715, 0.64799476, 0.64822716, 0.64856493,\n",
       "         0.65075624, 0.65156895, 0.653054  , 0.65436006, 0.65507919,\n",
       "         0.65555573, 0.65649909, 0.6565032 , 0.65780115, 0.65798569,\n",
       "         0.65965456, 0.66086888, 0.66169965, 0.6618377 , 0.66465759,\n",
       "         0.6646657 , 0.66484106, 0.66622555, 0.66684735, 0.6680367 ,\n",
       "         0.66827321, 0.66937453, 0.67180228, 0.67333543, 0.67442936,\n",
       "         0.67477667, 0.67479825, 0.67615247, 0.67693114, 0.68043977,\n",
       "         0.68264782, 0.68421745, 0.68466854, 0.6850276 , 0.68625331,\n",
       "         0.68696821, 0.68760169, 0.68818605, 0.68826377, 0.68868971,\n",
       "         0.68901944, 0.68983674, 0.69129598, 0.69200742, 0.69415319,\n",
       "         0.69557214, 0.69589996, 0.69655836, 0.69699347, 0.69769466,\n",
       "         0.69898808, 0.69946754, 0.70001626, 0.70154727, 0.70401514,\n",
       "         0.70441085, 0.7053389 , 0.70663679, 0.71187961, 0.71197212,\n",
       "         0.71277463, 0.71371865, 0.71459156, 0.71468842, 0.7160759 ,\n",
       "         0.71609712, 0.7172147 , 0.71811169, 0.71875131, 0.72019958,\n",
       "         0.72124821, 0.7218532 , 0.72187519, 0.72574544, 0.72662187,\n",
       "         0.72694027, 0.72792768, 0.7298224 , 0.73194927, 0.73199511,\n",
       "         0.73256111, 0.73650146, 0.7381804 , 0.73888773, 0.73956513,\n",
       "         0.73974299, 0.74000251, 0.74030417, 0.7419709 , 0.74469304,\n",
       "         0.744807  , 0.74529886, 0.74534303, 0.74597263, 0.74694943,\n",
       "         0.74772108, 0.74857569, 0.74906886, 0.74957645, 0.74976885,\n",
       "         0.75119019, 0.75143462, 0.75226367, 0.7539711 , 0.75441325,\n",
       "         0.75452006, 0.75652671, 0.7572087 , 0.75896209, 0.75900471,\n",
       "         0.75943005, 0.75992346, 0.76132107, 0.76362693, 0.76393223,\n",
       "         0.76437813, 0.77086639, 0.77247858, 0.77341712, 0.77484715,\n",
       "         0.77527666, 0.77596253, 0.77670407, 0.77989566, 0.78441393,\n",
       "         0.78446728, 0.78543401, 0.78646803, 0.78724462, 0.78775769,\n",
       "         0.7886135 , 0.78900445, 0.78915179, 0.79143906, 0.79214096,\n",
       "         0.79238129, 0.7926048 , 0.79305881, 0.79484403, 0.79609132,\n",
       "         0.79859662, 0.79914629, 0.79944563, 0.79972374, 0.79996896,\n",
       "         0.8000859 , 0.80065548, 0.80097693, 0.80135429, 0.80506778,\n",
       "         0.80618131, 0.80665594, 0.80760658, 0.80799782, 0.80805755,\n",
       "         0.80894101, 0.8102839 , 0.81149232, 0.8120991 , 0.81269389,\n",
       "         0.81315958, 0.81383967, 0.81770402, 0.81858408, 0.81878877,\n",
       "         0.82040024, 0.82191414, 0.82443273, 0.82481587, 0.82689375,\n",
       "         0.82721984, 0.82856309, 0.82919455, 0.82976127, 0.82984245,\n",
       "         0.83390713, 0.83524752, 0.83602738, 0.83823466, 0.83825386,\n",
       "         0.83961993, 0.84043086, 0.84068143, 0.84179831, 0.8419677 ,\n",
       "         0.84214497, 0.84344709, 0.84364367, 0.84545034, 0.84545386,\n",
       "         0.84637439, 0.84723556, 0.84776258, 0.84797072, 0.8483516 ,\n",
       "         0.84976596, 0.85144687, 0.85251617, 0.85754842, 0.85907602,\n",
       "         0.85953403, 0.86020195, 0.86054707, 0.86155438, 0.86164784,\n",
       "         0.861673  , 0.86315614, 0.86438942, 0.864465  , 0.86541021,\n",
       "         0.86579978, 0.86734521, 0.86775303, 0.86894166, 0.86958206,\n",
       "         0.86965334, 0.87347531, 0.87365085, 0.87382638, 0.8742519 ,\n",
       "         0.87479413, 0.87575573, 0.87745428, 0.8791641 , 0.87942064,\n",
       "         0.87949932, 0.87968206, 0.8838371 , 0.8840524 , 0.88518751,\n",
       "         0.88842547, 0.88908398, 0.88913476, 0.89004624, 0.89087987,\n",
       "         0.89233667, 0.89277351, 0.89341128, 0.89375877, 0.89400339,\n",
       "         0.89628011, 0.89668953, 0.89738995, 0.89755511, 0.89805436,\n",
       "         0.89810854, 0.89895248, 0.9011718 , 0.90123379, 0.90186197,\n",
       "         0.90244067, 0.90321624, 0.90423226, 0.90454185, 0.90505683,\n",
       "         0.90853596, 0.90861559, 0.91070104, 0.91181767, 0.91425061,\n",
       "         0.91437626, 0.91503954, 0.9164803 , 0.91690516, 0.91838866,\n",
       "         0.9189378 , 0.91899967, 0.92062747, 0.92087162, 0.92168146,\n",
       "         0.92226022, 0.92345595, 0.92476088, 0.92523128, 0.92795908,\n",
       "         0.92798221, 0.92928946, 0.93069255, 0.93264455, 0.93537331,\n",
       "         0.93562663, 0.93758798, 0.93903738, 0.94083238, 0.94108903,\n",
       "         0.9413029 , 0.94184113, 0.94200861, 0.94618082, 0.94700468,\n",
       "         0.94806331, 0.95275903, 0.95431721, 0.9598822 , 0.96120012])}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.precision_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9919a7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_threshold = 0.99\n",
    "precisions = imputer.precision_thresholds['1.0']['precisions']\n",
    "thresholds = imputer.precision_thresholds['1.0']['thresholds']\n",
    "precision_above = (precisions >= precision_threshold).nonzero()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02ef06c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6890873908996582"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds[min(precision_above, len(thresholds)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42cee6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(precision_above, len(thresholds)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be4a241e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c1274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
